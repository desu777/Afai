# ==========================================
# AQUAFOREST RAG SYSTEM - ENVIRONMENT VARIABLES
# ==========================================
# Copy this file to .env and fill in your actual values
# DO NOT commit .env file to git - it contains sensitive API keys

# ==========================================
# üîß DEVELOPMENT CONFIGURATION
# ==========================================
TEST_ENV=true
DISABLE_BUSINESS_MAPPINGS=false
ENABLE_COMPETITORS_ONLY=false

# ==========================================
# üóÑÔ∏è PINECONE VECTOR DATABASE
# ==========================================
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_INDEX_NAME=aquaforest
PINECONE_ENVIRONMENT=us-east-1

# ==========================================
# ü§ñ OPENROUTER API CONFIGURATION (Per-Node)
# ==========================================
# Each workflow component uses its own API key for load balancing

# API Keys (get from https://openrouter.ai/keys)
INTENT_DETECTOR_API=sk-or-v1-your_key_here
BUSINESS_REASONER_API=sk-or-v1-your_key_here
QUERY_OPTIMIZER_API=sk-or-v1-your_key_here
RESPONSE_FORMATTER_API=sk-or-v1-your_key_here
FOLLOW_UP_API=sk-or-v1-your_key_here

# Model Selection per Component
INTENT_DETECTOR_MODEL=google/gemini-2.5-flash-preview-05-20
BUSINESS_REASONER_MODEL=google/gemini-2.5-flash-preview-05-20
QUERY_OPTIMIZER_MODEL=google/gemini-2.5-flash-preview-05-20
RESPONSE_FORMATTER_MODEL=google/gemini-2.5-flash-preview-05-20
FOLLOW_UP_MODEL=google/gemini-2.0-flash-001

# ==========================================
# üì∏ IMAGE ANALYSIS CONFIGURATION
# ==========================================
IMAGE_API=sk-or-v1-your_image_api_key_here
IMAGE_MODEL=google/gemini-2.5-flash-preview-05-20

# ==========================================
# üìÑ ICP ANALYSIS CONFIGURATION
# ==========================================
ICP_API=sk-or-v1-your_icp_api_key_here
ICP_MODEL=google/gemini-2.5-flash-preview-05-20



# ==========================================
# üîë OPENAI CONFIGURATION
# ==========================================
# Used for embeddings and fallback
OPENAI_API_KEY=sk-proj-your_openai_key_here
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
OPENAI_TEMPERATURE=0.3
OPENAI_MAX_TOKENS=16384

# ==========================================
# ‚öôÔ∏è APPLICATION SETTINGS
# ==========================================
DEFAULT_K_VALUE=12
ENHANCED_K_VALUE=12
SUPPORTED_LANGUAGES=pl,en,de,fr,es,it,others
PRODUCTS_FILE_PATH=data/products.json

# ==========================================
# üöÄ PINECONE PARALLEL SEARCH OPTIMIZATION
# ==========================================
# Enable parallel search for better performance
ENABLE_PARALLEL_SEARCH=true

# Concurrent processing limits (Pinecone recommended: max 4)
MAX_CONCURRENT_QUERIES=4
MAX_CONCURRENT_EMBEDDINGS=4

# Pinecone connection pool optimization
PINECONE_POOL_THREADS=50
PINECONE_CONNECTION_POOL_MAX=50

# ==========================================
# üåê CORS & SERVER CONFIGURATION
# ==========================================
CORS_ORIGINS=http://localhost:3000,http://localhost:3001,http://localhost:8080,http://127.0.0.1:3000

# ==========================================
# üîí RATE LIMITING & SECURITY
# ==========================================
ENABLE_RATE_LIMITING=true
RATE_LIMIT_STORAGE=memory://

# Rate Limits per Tier
TIER1_RATE_LIMIT=20/minute     # Chat endpoints (/chat, /chat/stream)
TIER2_RATE_LIMIT=60/minute     # Analytics & session endpoints
TIER3_RATE_LIMIT=200/minute    # Basic endpoints (/health, /feedback)
VISION_RATE_LIMIT=10/minute    # Vision API endpoint
CSV_EXPORT_LIMIT=10/hour       # CSV export endpoints
GLOBAL_RATE_LIMIT=100/minute   # Fallback for unspecified endpoints

# IP Filtering (optional - leave empty to disable)
IP_WHITELIST=
IP_BLACKLIST=

# Auto-blacklisting Configuration
AUTO_BLACKLIST_ENABLED=true      # Enable automatic IP blacklisting
VIOLATION_THRESHOLD=2            # Number of rate limit violations before blacklist
BLACKLIST_DURATION_HOURS=24      # Hours to keep IP blacklisted
VIOLATION_WINDOW_HOURS=24        # Time window to count violations

# ==========================================
# üí¨ FACEBOOK MESSENGER INTEGRATION
# ==========================================
MESSENGER_ON=true
MESSENGER_TOKEN=your_facebook_page_access_token_here
MESSENGER_VERIFY_TOKEN=aquaforest_webhook_2025
FACEBOOK_API_VERSION=v22.0

# ==========================================
# üìä ANALYTICS & MONITORING
# ==========================================
# Analytics are automatically enabled with SQLite database
# Database file: aquaforest_analytics.db (created automatically)

# ==========================================
# üöÄ GOOGLE CLOUD VERTEX AI (GEMINI)
# ==========================================
# Jak skonfigurowaƒá Vertex AI zamiast OpenRouter:

# KROK 1: Id≈∫ na https://console.cloud.google.com
# KROK 2: Utw√≥rz projekt (lub wybierz istniejƒÖcy)
# KROK 3: W≈ÇƒÖcz "Vertex AI API" w APIs & Services  
# KROK 4: Utw√≥rz API Key w APIs & Services > Credentials
# KROK 5: Wpisz dane poni≈ºej:

GOOGLE_CLOUD_PROJECT_ID=twoj-project-id-tutaj
GOOGLE_CLOUD_API_KEY=twoj-api-key-tutaj  
GOOGLE_CLOUD_LOCATION=europe-west1

# üåç DOSTƒòPNE REGIONY (wybierz jeden):
# europe-west1 - Belgia (najlepszy dla Polski)
# europe-west3 - Frankfurt  
# us-central1  - USA

# ==========================================
# ü§ñ WYB√ìR MODELI GEMINI
# ==========================================
# Domy≈õlnie u≈ºywa OpenRouter. ≈ªeby w≈ÇƒÖczyƒá Vertex AI dla wƒôz≈Ça:

# Globalny provider (openrouter lub gemini)
LLM_PROVIDER=openrouter

# W≈ÇƒÖcz Vertex AI dla wybranych wƒôz≈Ç√≥w (usu≈Ñ # ≈ºeby w≈ÇƒÖczyƒá):
# INTENT_DETECTOR_PROVIDER=gemini      # Wykrywanie intencji  
# BUSINESS_REASONER_PROVIDER=gemini    # Logika biznesowa
# QUERY_OPTIMIZER_PROVIDER=gemini     # Optymalizacja zapyta≈Ñ
# RESPONSE_FORMATTER_PROVIDER=gemini  # Formatowanie odpowiedzi
# FOLLOW_UP_PROVIDER=gemini           # Ocena kontynuacji
# IMAGE_PROVIDER=gemini               # Analiza obraz√≥w
# ICP_PROVIDER=gemini                 # Analiza parametr√≥w wody

# ==========================================
# üìä DOSTƒòPNE MODELE VERTEX AI
# ==========================================
# gemini-2.5-flash - szybki, tani, dobry do wiƒôkszo≈õci zada≈Ñ
# gemini-2.5-pro   - lepsze my≈õlenie, dro≈ºszy, do skomplikowanych zada≈Ñ

# ==========================================
# ü§ñ KONFIGURACJA MODELI VERTEX AI (Per-node)
# ==========================================
# üìä DOSTƒòPNE MODELE:
# gemini-2.5-flash - Szybki, tani, dobry do wszystkich zada≈Ñ
# gemini-2.5-pro   - Lepsze my≈õlenie, dro≈ºszy, do skomplikowanych analiz

# üöÄ FAST-THINKING CONFIGURATION (Wszystkie wƒôz≈Çy na flash - szybkie i tanie)
INTENT_DETECTOR_GEMINI_MODEL=gemini-2.5-flash
BUSINESS_REASONER_GEMINI_MODEL=gemini-2.5-flash
QUERY_OPTIMIZER_GEMINI_MODEL=gemini-2.5-flash
RESPONSE_FORMATTER_GEMINI_MODEL=gemini-2.5-flash
FOLLOW_UP_GEMINI_MODEL=gemini-2.5-flash
IMAGE_GEMINI_MODEL=gemini-2.5-flash
ICP_GEMINI_MODEL=gemini-2.5-flash

# üíé PREMIUM CONFIGURATION (Odkomentuj dla najlepszej jako≈õci - dro≈ºej)
# INTENT_DETECTOR_GEMINI_MODEL=gemini-2.5-flash
# BUSINESS_REASONER_GEMINI_MODEL=gemini-2.5-pro  
# QUERY_OPTIMIZER_GEMINI_MODEL=gemini-2.5-flash
# RESPONSE_FORMATTER_GEMINI_MODEL=gemini-2.5-flash
# FOLLOW_UP_GEMINI_MODEL=gemini-2.5-pro
# IMAGE_GEMINI_MODEL=gemini-2.5-flash
# ICP_GEMINI_MODEL=gemini-2.5-pro

# ‚öñÔ∏è BALANCED CONFIGURATION (Odkomentuj dla balansu szybko≈õƒá/jako≈õƒá)
# INTENT_DETECTOR_GEMINI_MODEL=gemini-2.5-flash
# BUSINESS_REASONER_GEMINI_MODEL=gemini-2.5-pro  
# QUERY_OPTIMIZER_GEMINI_MODEL=gemini-2.5-flash
# RESPONSE_FORMATTER_GEMINI_MODEL=gemini-2.5-flash
# FOLLOW_UP_GEMINI_MODEL=gemini-2.5-flash
# IMAGE_GEMINI_MODEL=gemini-2.5-flash
# ICP_GEMINI_MODEL=gemini-2.5-flash

# ==========================================
# üéõÔ∏è PARAMETRY GENEROWANIA VERTEX AI (ZAKOMENTOWANE)
# ==========================================
# Aktualnie u≈ºywamy domy≈õlnych parametr√≥w Gemini (temp=1.0, top_p=0.95, top_k=default)
# Odkomentuj poni≈ºsze je≈õli potrzebujesz dostroiƒá odpowiedzi:
# Zobacz: backend/src/temperature_topp_topk_gemini.md dla szczeg√≥≈Ç√≥w

# üå°Ô∏è TEMPERATURE - Kontroluje losowo≈õƒá (0.0 = deterministyczne, 2.0 = bardzo kreatywne)
# GEMINI_TEMPERATURE=1.0

# üé≤ TOP_P - Nucleus sampling (0.0-1.0, domy≈õlnie 0.95)
# GEMINI_TOP_P=0.95

# üî¢ TOP_K - Ograniczenie do K najbardziej prawdopodobnych token√≥w
# GEMINI_TOP_K=

# ==========================================
# üí° PRZYK≈ÅADY KONFIGURACJI  
# ==========================================

# PRZYK≈ÅAD 1: Tylko OpenRouter (domy≈õlnie)
# LLM_PROVIDER=openrouter
# (nie zmieniaj nic wiƒôcej)

# PRZYK≈ÅAD 2: Szybkie zadania na Vertex AI  
# LLM_PROVIDER=openrouter
# INTENT_DETECTOR_PROVIDER=gemini
# RESPONSE_FORMATTER_PROVIDER=gemini
# (szybkie wykrywanie + formatowanie na Vertex AI, reszta OpenRouter)

# PRZYK≈ÅAD 3: Wszystko na Vertex AI
# LLM_PROVIDER=gemini  
# (wszystkie wƒôz≈Çy u≈ºywajƒÖ Vertex AI, fallback na OpenRouter przy b≈Çƒôdach)

# ==========================================
# üöÄ PRODUCTION NOTES
# ==========================================
# 1. Set TEST_ENV=false in production
# 2. Use Redis for RATE_LIMIT_STORAGE in production: redis://localhost:6379
# 3. Configure proper CORS_ORIGINS for your domain
# 4. Set up monitoring for rate limit violations
# 5. Regularly backup aquaforest_analytics.db