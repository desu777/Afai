# ==========================================
# AQUAFOREST RAG SYSTEM - ENVIRONMENT VARIABLES
# ==========================================
# Copy this file to .env and fill in your actual values
# DO NOT commit .env file to git - it contains sensitive API keys

# ==========================================
# üîß DEVELOPMENT CONFIGURATION
# ==========================================
TEST_ENV=true
DISABLE_BUSINESS_MAPPINGS=false
ENABLE_COMPETITORS_ONLY=false

# ==========================================
# üóÑÔ∏è PINECONE VECTOR DATABASE
# ==========================================
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_INDEX_NAME=aquaforest
PINECONE_ENVIRONMENT=us-east-1

# ==========================================
# ü§ñ OPENROUTER API CONFIGURATION (Per-Node)
# ==========================================
# Each workflow component uses its own API key for load balancing

# API Keys (get from https://openrouter.ai/keys)
INTENT_DETECTOR_API=sk-or-v1-your_key_here
BUSINESS_REASONER_API=sk-or-v1-your_key_here
QUERY_OPTIMIZER_API=sk-or-v1-your_key_here
RESPONSE_FORMATTER_API=sk-or-v1-your_key_here
FOLLOW_UP_API=sk-or-v1-your_key_here

# Model Selection per Component
INTENT_DETECTOR_MODEL=google/gemini-2.5-flash-preview-05-20
BUSINESS_REASONER_MODEL=google/gemini-2.5-flash-preview-05-20
QUERY_OPTIMIZER_MODEL=google/gemini-2.5-flash-preview-05-20
RESPONSE_FORMATTER_MODEL=google/gemini-2.5-flash-preview-05-20
FOLLOW_UP_MODEL=google/gemini-2.0-flash-001

# ==========================================
# üì∏ IMAGE ANALYSIS CONFIGURATION
# ==========================================
IMAGE_API=sk-or-v1-your_image_api_key_here
IMAGE_MODEL=google/gemini-2.5-flash-preview-05-20

# ==========================================
# üìÑ ICP ANALYSIS CONFIGURATION
# ==========================================
ICP_API=sk-or-v1-your_icp_api_key_here
ICP_MODEL=google/gemini-2.5-flash-preview-05-20

# ==========================================
# üåê WEB SCRAPING CONFIGURATION
# ==========================================
HYPERBROWSER_API_KEY=your_hyperbrowser_api_key_here

# ==========================================
# üîë OPENAI CONFIGURATION
# ==========================================
# Used for embeddings and fallback
OPENAI_API_KEY=sk-proj-your_openai_key_here
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
OPENAI_TEMPERATURE=0.3
OPENAI_MAX_TOKENS=16384

# ==========================================
# ‚öôÔ∏è APPLICATION SETTINGS
# ==========================================
DEFAULT_K_VALUE=12
ENHANCED_K_VALUE=12
SUPPORTED_LANGUAGES=pl,en,de,fr,es,it,others
PRODUCTS_FILE_PATH=data/products.json

# ==========================================
# üöÄ PINECONE PARALLEL SEARCH OPTIMIZATION
# ==========================================
# Enable parallel search for better performance
ENABLE_PARALLEL_SEARCH=true

# Concurrent processing limits (Pinecone recommended: max 4)
MAX_CONCURRENT_QUERIES=4
MAX_CONCURRENT_EMBEDDINGS=4

# Pinecone connection pool optimization
PINECONE_POOL_THREADS=50
PINECONE_CONNECTION_POOL_MAX=50

# ==========================================
# üåê CORS & SERVER CONFIGURATION
# ==========================================
CORS_ORIGINS=http://localhost:3000,http://localhost:3001,http://localhost:8080,http://127.0.0.1:3000

# ==========================================
# üîí RATE LIMITING & SECURITY
# ==========================================
ENABLE_RATE_LIMITING=true
RATE_LIMIT_STORAGE=memory://

# Rate Limits per Tier
TIER1_RATE_LIMIT=20/minute     # Chat endpoints (/chat, /chat/stream)
TIER2_RATE_LIMIT=60/minute     # Analytics & session endpoints
TIER3_RATE_LIMIT=200/minute    # Basic endpoints (/health, /feedback)
VISION_RATE_LIMIT=10/minute    # Vision API endpoint
CSV_EXPORT_LIMIT=10/hour       # CSV export endpoints
GLOBAL_RATE_LIMIT=100/minute   # Fallback for unspecified endpoints

# IP Filtering (optional - leave empty to disable)
IP_WHITELIST=
IP_BLACKLIST=

# Auto-blacklisting Configuration
AUTO_BLACKLIST_ENABLED=true      # Enable automatic IP blacklisting
VIOLATION_THRESHOLD=2            # Number of rate limit violations before blacklist
BLACKLIST_DURATION_HOURS=24      # Hours to keep IP blacklisted
VIOLATION_WINDOW_HOURS=24        # Time window to count violations

# ==========================================
# üí¨ FACEBOOK MESSENGER INTEGRATION
# ==========================================
MESSENGER_ON=true
MESSENGER_TOKEN=your_facebook_page_access_token_here
MESSENGER_VERIFY_TOKEN=aquaforest_webhook_2025
FACEBOOK_API_VERSION=v22.0

# ==========================================
# üìä ANALYTICS & MONITORING
# ==========================================
# Analytics are automatically enabled with SQLite database
# Database file: aquaforest_analytics.db (created automatically)

# ==========================================
# üöÄ GOOGLE GEMINI API CONFIGURATION (2025)
# ==========================================
# Alternative to OpenRouter - supports dual API setup
# Get your API key from: https://aistudio.google.com/apikey

# Gemini API Key (Default/Fallback)
GEMINI_API_KEY=your_gemini_api_key_here

# üî• PER-NODE GEMINI API KEYS (DUAL API OPTIMIZATION)
# Use separate API keys for different nodes to maximize free tier usage
# Each free tier key = 10 RPM + 500 req/day
# GEMINI_API_KEY_BUSINESS=your_business_reasoner_gemini_key
# GEMINI_API_KEY_RESPONSE=your_response_formatter_gemini_key
# GEMINI_API_KEY_INTENT=your_intent_detector_gemini_key
# GEMINI_API_KEY_QUERY=your_query_optimizer_gemini_key
# GEMINI_API_KEY_FOLLOWUP=your_followup_evaluator_gemini_key
# GEMINI_API_KEY_IMAGE=your_image_analysis_gemini_key
# GEMINI_API_KEY_ICP=your_icp_analysis_gemini_key

# Global provider selection (openrouter or gemini)
LLM_PROVIDER=openrouter

# Per-node provider overrides (optional)
# Uncomment to use Gemini for specific workflow components
# INTENT_DETECTOR_PROVIDER=gemini
# BUSINESS_REASONER_PROVIDER=gemini
# QUERY_OPTIMIZER_PROVIDER=gemini
# RESPONSE_FORMATTER_PROVIDER=gemini
# FOLLOW_UP_PROVIDER=gemini
# IMAGE_PROVIDER=gemini
# ICP_PROVIDER=gemini

# ==========================================
# ü§ñ GEMINI 2.5 MODEL SELECTION
# ==========================================
# Choose models per component (only used when provider=gemini)

# Default model for all components
GEMINI_DEFAULT_MODEL=gemini-2.5-flash

# Per-node model overrides (optional)
# INTENT_DETECTOR_GEMINI_MODEL=gemini-2.5-flash   # Speed optimized
# BUSINESS_REASONER_GEMINI_MODEL=gemini-2.5-flash   # Reasoning optimized
# QUERY_OPTIMIZER_GEMINI_MODEL=gemini-2.5-flash   # Speed optimized
# RESPONSE_FORMATTER_GEMINI_MODEL=gemini-2.5-flash # Speed optimized
# FOLLOW_UP_GEMINI_MODEL=gemini-2.5-pro           # Reasoning optimized
# IMAGE_GEMINI_MODEL=gemini-2.5-flash             # Vision optimized
# ICP_GEMINI_MODEL=gemini-2.5-pro                 # Analysis optimized

# ==========================================
# üß† GEMINI THINKING CONFIGURATION
# ==========================================
# Gemini 2.5 Flash has thinking ENABLED BY DEFAULT
# Only set thinking_budget if you want to disable (0) or increase (1000+)
# Leave empty/unset = use Gemini's default thinking (recommended)

# Default thinking budget (leave empty for Gemini default)
# GEMINI_DEFAULT_THINKING_BUDGET=

# Per-node thinking budget (only set if needed)
# INTENT_DETECTOR_THINKING_BUDGET=0      # Disable for speed (free tier)
# BUSINESS_REASONER_THINKING_BUDGET=8000  # Increase for better reasoning
# QUERY_OPTIMIZER_THINKING_BUDGET=0      # Disable for speed
# RESPONSE_FORMATTER_THINKING_BUDGET=0   # Disable for speed
# FOLLOW_UP_THINKING_BUDGET=5000         # Increase for better analysis
# IMAGE_THINKING_BUDGET=                 # Leave default
# ICP_THINKING_BUDGET=7000               # Increase for better analysis

# ==========================================
# üìã PRACTICAL CONFIGURATION EXAMPLES
# ==========================================

# EXAMPLE 1: Free Tier Setup (10 RPM, 500 req/day)
# Use only Response Formatter with Gemini for minimal usage
# LLM_PROVIDER=openrouter
# RESPONSE_FORMATTER_PROVIDER=gemini
# RESPONSE_FORMATTER_THINKING_BUDGET=0  # Disable thinking for speed
# GEMINI_API_KEY=your_gemini_api_key_here

# EXAMPLE 2: Paid Tier Setup (1000 RPM)
# Use Gemini globally with default thinking
# LLM_PROVIDER=gemini
# GEMINI_API_KEY=your_gemini_api_key_here

# EXAMPLE 3: Mixed Setup - Speed vs Reasoning
# Fast tasks on Gemini, complex tasks on OpenRouter
# LLM_PROVIDER=openrouter
# INTENT_DETECTOR_PROVIDER=gemini
# RESPONSE_FORMATTER_PROVIDER=gemini
# INTENT_DETECTOR_THINKING_BUDGET=0
# RESPONSE_FORMATTER_THINKING_BUDGET=0
# GEMINI_API_KEY=your_gemini_api_key_here

# EXAMPLE 4: Cost Optimization
# Use Gemini for simple tasks, OpenRouter for complex reasoning
# LLM_PROVIDER=openrouter
# INTENT_DETECTOR_PROVIDER=gemini        # Cheaper classification
# QUERY_OPTIMIZER_PROVIDER=gemini        # Cheaper optimization
# RESPONSE_FORMATTER_PROVIDER=gemini     # Cheaper formatting
# GEMINI_API_KEY=your_gemini_api_key_here

# EXAMPLE 5: DUAL API KEY SETUP (BEAST MODE) üî•
# Business Reasoner + Response Formatter with max thinking on separate keys
# Automatic fallback to OpenRouter on rate limit/error
# LLM_PROVIDER=openrouter
# BUSINESS_REASONER_PROVIDER=gemini
# RESPONSE_FORMATTER_PROVIDER=gemini
# BUSINESS_REASONER_THINKING_BUDGET=24000    # Max thinking for business logic
# RESPONSE_FORMATTER_THINKING_BUDGET=24000   # Max thinking for formatting
# GEMINI_API_KEY_BUSINESS=your_business_api_key_here
# GEMINI_API_KEY_RESPONSE=your_response_api_key_here
# # Smart fallback: Gemini (10 RPM + 500/day) ‚Üí OpenRouter (unlimited)
# # Total capacity: 20 RPM Gemini + OpenRouter fallback = Zero downtime

# ==========================================
# üìä GEMINI RATE LIMITS & RECOMMENDATIONS
# ==========================================
# Free tier: 10 RPM (requests per minute), 500 requests/day
# Paid tier: 1000 RPM, higher daily limits
# 
# THINKING BUDGET GUIDE:
# - Don't set = use Gemini's default thinking (recommended)
# - 0 = disable thinking (free tier, maximum speed)
# - 1000-8000 = increase thinking (paid tier, better quality)
# - 10000+ = deep thinking (best quality, slowest)
#
# FREE TIER RECOMMENDATIONS:
# - Use only 1-2 nodes with Gemini
# - Set thinking_budget=0 for maximum speed
# - Monitor usage with TEST_ENV=true
# - Good starting node: RESPONSE_FORMATTER_PROVIDER=gemini
#
# PAID TIER RECOMMENDATIONS:
# - Can use all nodes with Gemini
# - Leave thinking_budget unset for balanced performance
# - Or increase thinking_budget for better quality on complex tasks
# - Mix providers based on task complexity for optimal cost/performance
#
# PRODUCTION TIPS:
# - Use Gemini for speed-critical tasks (intent detection, formatting)
# - Use OpenRouter for reasoning-heavy tasks (business logic, analysis)
# - Monitor costs and adjust thinking budgets accordingly
# - DUAL API KEY BENEFITS:
#   * 2x rate limits (10 RPM per key = 20 RPM total)
#   * 2x daily quotas (500 req/day per key = 1000 req/day total)
#   * Automatic fallback to OpenRouter prevents downtime
#   * Zero-config rate limit management with smart fallback

# ==========================================
# üöÄ PRODUCTION NOTES
# ==========================================
# 1. Set TEST_ENV=false in production
# 2. Use Redis for RATE_LIMIT_STORAGE in production: redis://localhost:6379
# 3. Configure proper CORS_ORIGINS for your domain
# 4. Set up monitoring for rate limit violations
# 5. Regularly backup aquaforest_analytics.db